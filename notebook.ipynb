{
  "metadata": {
    "kernelspec": {
      "name": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.5.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "Import Libraries & Configure Visualizations",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Ignore Warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#Handle tabular data & matrices\nimport numpy as np\nimport pandas as pd\n\n#Modelling Algorithms\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n\n#Helpers for Modelling\nfrom sklearn.preprocessing import Imputer, Normalizer, scale\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.feature_selection import RFECV\n\n#Visualization\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\n#import statsmodels as sns\nimport seaborn as sns\n\n#Configure Visualizations\n%matplotlib inline\nmpl.style.use('ggplot')\nsns.set_style('white')\npylab.rcParams[ 'figure.figsize'] = 8 , 6",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Define Helper Functions",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Helper functions for making good looking plots\ndef plot_histograms(df, variables, n_rows, n_cols):\n    fig = plt.figure(figsize = (16, 12))\n    for i, var_name in enumerate(variables):\n        ax = fig.add_subplot(n_rows, n_cols, i+1)\n        df[var_name].hist(bins = 10, ax = ax)\n        ax.set_title('Skew: ' + str(round ( float( df[var_name].skew() ),) ) )\n        ax.set_xticklabels( [], visible = False)\n        ax.set_yticklabels( [], visible = False)\n        fig.tight_layout()\n        plt.show()\n\ndef plot_distribution( df , var , target , **kwargs ):\n    row = kwargs.get( 'row' , None )\n    col = kwargs.get( 'col' , None )\n    facet = sns.FacetGrid( df , hue=target , aspect=4 , row = row , col = col )\n    facet.map( sns.kdeplot , var , shade= True )\n    facet.set( xlim=( 0 , df[ var ].max() ) )\n    facet.add_legend()\n\ndef plot_categories(df, cat, target, **kwargs):\n    row = kwargs.get('row', None)\n    col = kwargs.get('col', None)\n    facet = sns.FacetGrid(df, row = row, col = col)\n    facet.map(sns.barplot, cat, target)\n    facet.add_legend()\n\ndef plot_correlation_map(df):\n    corr = titanic.corr()\n    _ , ax = plt.subplots(figsize = (12, 10))\n    cmap = sns.diverging_palette(220,10,as_cmap = True)\n    _ = sns.heatmap(corr, cmap = cmap, square = True, cbar_kws = {'shrink': .0}, ax = ax, annot = True, annot_kws = {'fontsize': 12})\n\ndef describe_more(df):\n    var = []; l = []; t = []\n    for x in df:\n        var.append(x)\n        l.append(len(pd.value_counts(df[x])))\n        l.append(df[x].dtypes)\n    levels = pd.DataFrame({'Variable': var, 'Levels': l, 'Datatype': t})\n    levels.sort_values(by = 'Levels', implace = True)\n    return levels\n\ndef plot_variable_importance(X, y):\n    tree = DecisionTreeClassifier(random_state = 99)\n    tree.fit(X, y)\n    plot_model_var_imp(tree, X, y)\n\ndef plot_model_var_imp(model, X, y):\n    imp = pd.DataFrame(model.feature_importances_, columns = ['Importance'], index = X.columns)\n    imp = imp.sort_values(['Importance'], ascending = True)\n    imp[:10].plot(kind = 'barh')\n    print(model.score(X, y))\n\n#def determine_Rich(money):\n #   if(money['Title'] == \"Royalty\"):\n  #      return True\n   # elif(money['Pclass'] == 1):\n    #    return True\n    #elif(money['Fare'] > money['Fare'].quantile(0.75)):\n     #   return True\n    #else:\n     #   return False\n\n#def determine_Middle(money):\n    #if(money['Pclass'] == 2):\n     #   return True\n    #elif(money['Fare'].quantile(0.25)<= money['Fare'] <= money['Fare'].quantile(0.75)):\n     #   return True\n    #else:\n     #   return False\n\n#def determine_Poor(money):\n   # if(money['Pclass'] == 3):\n    #    return True\n    #elif(money['Fare'] < money['Fare'].quantile(0.25)):\n    #    return True\n    #else:\n      #  return False",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Import the data and peak at it",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "train = pd.read_csv(\"../input/train.csv\") #change filepath later\ntest = pd.read_csv('../input/test.csv') #change filepath later\n\nfull = train.append(test, ignore_index = True)\ntitanic = full[ :891 ]\n\ndel train, test\nprint('Datasets:', 'full:', full.shape, 'titanic:', titanic.shape)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Peak at the data",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "titanic.head()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Describe the full data",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "titanic.describe()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Run the main function",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Plot correlation heat map\nplot_correlation_map(titanic)\n\n#Plot distribution of Age of passengers\n#plot_distribution(titanic, var = 'Age', target = 'Survived', row = 'Sex')\n\n#Plot distribution of Fare of passengers\n#plot_distribution(titanic, var = 'Fare', target = 'Survived', row = 'Pclass')\n\n#Plot survival rate by embarked\nplot_categories(titanic, cat = 'Embarked', target = 'Survived')\n\n#Plot survival rate by Sex\nplot_categories(titanic, cat = 'Sex', target = 'Survived')\n\n#Plot survival rate by Pclass\nplot_categories(titanic, cat = 'Pclass', target = 'Survived')\n\n#Plot surivival rate by SibSp\nplot_categories(titanic, cat = 'SibSp', target = 'Survived')\n\n#Plot survival rate by Parch\nplot_categories(titanic, cat = 'Parch', target = 'Survived')",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Make sex into binary values 0 & 1 (needs to be numerical data)\nsex = pd.Series(np.where(full.Sex == 'male', 1, 0), name = 'Sex')\n\n#Create new variable for every unique embarked variable\nembarked = pd.get_dummies(full.Embarked, prefix = 'Embarked')\nembarked.head()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Create new variable for every unique value of Passenger Class\npclass = pd.get_dummies(full.Pclass, prefix = 'Pclass')\npclass.head()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "Fare = pd.DataFrame()\nFare['Fare'] = full.Fare.fillna(full.Fare.median())\nFare.describe()\nprint(Fare.isnull().any().any())",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Extracting title\ntitle = pd.DataFrame()\ntitle['Title'] = full['Name'].map( lambda name: name.split(',')[1].split('.')[0].strip())\nTitle_Dictionary = {\n        \"Capt\": \"Officer\",\n        \"Col\": \"Officer\",\n        \"Major\": \"Officer\",\n        \"Jonkheer\": \"Royalty\",\n        \"Don\": \"Royalty\",\n        \"Sir\": \"Royalty\",\n        \"Dr\": \"Officer\",\n        \"Rev\": \"Officer\",\n        \"the Countess\": \"Royalty\",\n        \"Dona\": \"Royalty\",\n        \"Mme\": \"Mrs\",\n        \"Mlle\": \"Miss\",\n        \"Ms\": \"Mrs\",\n        \"Mr\": \"Mr\",\n        \"Mrs\": \"Mrs\",\n        \"Miss\": \"Miss\",\n        \"Master\": \"Royalty\",\n        \"Lady\": \"Royalty\"\n}\nstuff = pd.DataFrame()\nstuff['Title'] = title.Title\ntitle['Title'] = title.Title.map(Title_Dictionary)\ntitle = pd.get_dummies(title.Title)\n#title pd.concat([title, titles_dummies], axis = 1)\ntitle.head()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Option 3: fill missing ages with medians that are seperated by group\nstuff['Sex'] = full.Sex\nstuff['Pclass'] = full.Pclass\nstuff['Age'] = full.Age\nstuff['Age'] = stuff.groupby(['Sex', 'Pclass', 'Title'])['Age'].transform(lambda x: x.fillna(x.median()))\nstuff['Age'] = stuff.Age.fillna(stuff.Age.median())\nAge = pd.DataFrame()\nAge['Age'] = stuff.Age\n\ndel stuff\nAge.describe()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Create family size variable\nfamily = pd.DataFrame()\n\nfamily['FamilySize'] = full['Parch'] + full['SibSp'] + 1\n\n#Single, small or large family\nfamily['Family_Single'] = family['FamilySize'].map(lambda s: 1 if s == 1 else 0)\nfamily['Family_Small'] = family['FamilySize'].map(lambda s: 1 if 2 <= s <= 4 else 0)\nfamily['Family_Large'] = family['FamilySize'].map(lambda s: 1 if 5 <= s else 0)\n\nfamily.head()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Create a wealth variable\ntitle = pd.DataFrame()\ntitle['Title'] = full['Name'].map( lambda name: name.split(',')[1].split('.')[0].strip())\nmoney = pd.DataFrame()\nmoney['Pclass'] = full.Pclass\nmoney['Fare'] = full.Fare\nmoney['Title'] = title.Title\nmoney['Rich'] = money['Pclass'].map(lambda s: 1 if s == 1 else 0)\nmoney['Middle'] = money['Pclass'].map(lambda s: 1 if s == 2 else 0)\nmoney['Poor'] = money['Pclass'].map(lambda s: 1 if s == 3 else 0)\nmoney.head()\n\nwealth = pd.DataFrame()\nwealth['Rich'] = money.Rich\nwealth['Middle'] = money.Middle\nwealth['Poor'] = money.Poor",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "\n#Create all datasets neccessary to test models\nPclass = pd.DataFrame()\nPclass = full.Pclass\nfull_X = pd.concat([Age, sex, Pclass, family, Fare], axis = 1)\nfull_X.head()\ntrain_valid_X = full_X[0:891]\ntrain_valid_Y = titanic.Survived\ntest_X = full_X[891:]\ntrain_X, valid_X, train_Y, valid_Y = train_test_split(train_valid_X, train_valid_Y, train_size = 0.7)\nprint (full_X.shape, train_X.shape, valid_X.shape, train_Y.shape, valid_Y.shape, test_X.shape)\n\nplot_variable_importance(train_X, train_Y)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Run several different models\nmodel1 = RandomForestClassifier(n_estimators = 100)\nmodel2 = KNeighborsClassifier(n_neighbors = 3)\nmodel3 = GradientBoostingClassifier()\nmodel4 = GaussianNB()\nmodel5 = LogisticRegression()\nmodel6 = SVC()\n\nmodel1.fit(train_X, train_Y)\nmodel2.fit(train_X, train_Y)\nmodel3.fit(train_X, train_Y)\nmodel4.fit(train_X, train_Y)\nmodel5.fit(train_X, train_Y)\nmodel6.fit(train_X, train_Y)\n\ntrain_score1 = model1.score(train_X, train_Y)\ntrain_score2 = model2.score(train_X, train_Y)\ntrain_score3 = model3.score(train_X, train_Y)\ntrain_score4 = model4.score(train_X, train_Y)\ntrain_score5 = model5.score(train_X, train_Y)\ntrain_score6 = model6.score(train_X, train_Y)\n    \nvalid_score1 = model1.score(valid_X, valid_Y)\nvalid_score2 = model2.score(valid_X, valid_Y)\nvalid_score3 = model3.score(valid_X, valid_Y)\nvalid_score4 = model4.score(valid_X, valid_Y)\nvalid_score5 = model5.score(valid_X, valid_Y)\nvalid_score6 = model6.score(valid_X, valid_Y)\n\n#Print out score comparisons\nprint(\"Train Data Score: Validation Data Score:\")\nprint(train_score1, valid_score1)\nprint(train_score2, valid_score2)\nprint(train_score3, valid_score3)\nprint(train_score4, valid_score4)\nprint(train_score5, valid_score5)\nprint(train_score6, valid_score5)\n\n#Hopefully find the Optimal Features for the model\nplot_model_var_imp(model1, train_X, train_Y)\n#rfecv = RFECV(estimator = model5, step = 1, cv = StratifiedKFold(train_Y, 2), scoring = 'accuracy')\n#rfecv.fit(train_X, train_Y)\n#print(rfecv.score(train_X, train_Y), rfecv.score(valid_X, Valid_Y))\n#print(\"Optimal number of features: %d\" % refecv.n_features_)\n\n#Plot number of features vs. cross Validcation Scores\n#plt.figure()\n#plt.xlabel(\"Number of features selected\")\n#plt.ylabel(\"Cross validation score (nb of correct classification\")\n#plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores)\n#plt.show()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Model 1\ntest_Y1 = model1.predict( test_X )\npassenger_id = full[891:].PassengerId\ntest1 = pd.DataFrame( { 'PassengerId': passenger_id , 'Survived': test_Y1 } )\ntest1.head()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Model 2\ntest_Y2 = model2.predict( test_X )\npassenger_id = full[891:].PassengerId\ntest2 = pd.DataFrame( { 'PassengerId': passenger_id , 'Survived': test_Y2 } )\ntest2.head()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Model 3\ntest_Y3 = model3.predict( test_X )\npassenger_id = full[891:].PassengerId\ntest3 = pd.DataFrame( { 'PassengerId': passenger_id , 'Survived': test_Y3 } )\ntest3.head()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Model 4\ntest_Y4 = model4.predict( test_X )\npassenger_id = full[891:].PassengerId\ntest4 = pd.DataFrame( { 'PassengerId': passenger_id , 'Survived': test_Y4 } )\ntest4.head()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Model 5\ntest_Y5 = model5.predict( test_X )\npassenger_id = full[891:].PassengerId\ntest5 = pd.DataFrame( { 'PassengerId': passenger_id , 'Survived': test_Y5 } )\ntest5.head()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Model 6\ntest_Y6 = model6.predict( test_X )\npassenger_id = full[891:].PassengerId\ntest6 = pd.DataFrame( { 'PassengerId': passenger_id , 'Survived': test_Y6 } )\ntest6.head()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Average all the different test data\ntest_total = test1.add(test2, fill_value = 0)\ntest_total2 = test3.add(test4, fill_value = 0)\ntest_total2 = test_total2.add(test6, fill_value = 0)\ntest_total = test_total.add(test5, fill_value = 0)\ntest_total = test_total.add(test_total2, fill_value = 0)\ntest_total = test_total.divide(6)\ntest_total['PassengerId'] = test_total['PassengerId'].astype(int)\ntest_total['Survived'] = test_total['Survived'].round(0)\ntest_total['Survived'] = test_total['Survived'].astype(int)\ntest_total.head()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "test_total.to_csv( 'titanic_pred.csv' , index = False )",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    }
  ]
}